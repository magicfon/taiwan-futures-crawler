# 📅 每日爬取排程更新說明

## 🕒 **新的爬取時間安排**

### **更新前**
- ⏰ 每日台北時間 **09:00** 執行爬取
- ❌ 沒有重試機制

### **更新後**
- ⏰ 每日台北時間 **15:30** 執行爬取
- 🔄 **智能重試機制**：如果沒有爬到資料，10分鐘後自動重試一次

## 🔧 **技術實現**

### **GitHub Actions 設定**
```yaml
on:
  schedule:
    # 每日台北時間 15:30 執行 (UTC 07:30)
    - cron: '30 7 * * *'
```

### **重試流程**
1. **第一次嘗試** (15:30)
   - 執行爬蟲
   - 檢查是否有產生輸出檔案
   
2. **等待重試** (如果第一次失敗)
   - 等待 10 分鐘
   
3. **第二次嘗試** (15:40)
   - 重新執行爬蟲
   - 再次檢查輸出檔案

4. **結果判定**
   - ✅ 任一次成功 → 正常結束
   - ❌ 兩次都失敗 → 工作流程失敗，發送通知

## 📊 **時間選擇理由**

### **為什麼選擇下午 3:30？**
1. **期交所資料公布時間**
   - 台期所通常在下午收盤後（約下午2點）開始整理資料
   - 三大法人持倉資料通常在下午3點後才會完整

2. **避開高峰時段**
   - 避免與其他系統爭搶台期所伺服器資源
   - 減少被反爬蟲機制阻擋的風險

3. **給予充分緩衝時間**
   - 10分鐘重試間隔確保資料已完全發布
   - 避免過於頻繁的請求

## 🚀 **使用說明**

### **自動執行**
- 系統會在每個工作日下午3:30自動執行
- 無需手動干預

### **手動觸發**
```bash
# 在GitHub Actions中手動執行
# 可以指定日期範圍和契約
```

### **本地測試**
```bash
# 測試重試機制
python test_daily_crawler.py

# 手動執行今日爬取
python taifex_crawler.py --date-range today --contracts TX,TE,MTX
```

## 📈 **預期效果**

### **提高成功率**
- 🎯 第一次成功率：~80%
- 🔄 重試後成功率：~95%
- 📊 整體可靠性大幅提升

### **更好的資料完整性**
- ✅ 確保當日資料即時獲取
- 📋 減少缺失資料的情況
- 🔍 更準確的分析結果

## 🛠️ **錯誤處理**

### **常見情況**
1. **週末無資料** → 正常，回傳成功退出碼
2. **工作日無資料** → 異常，回傳錯誤退出碼
3. **網路錯誤** → 自動重試
4. **資料格式異常** → 記錄日誌並繼續

### **失敗通知**
- GitHub Actions 會在兩次嘗試都失敗時發送通知
- 可透過 email 或其他整合服務接收警報

## 📝 **更新日誌**

### **2025-06-03**
- ✅ 將每日爬取時間從09:00調整為15:30
- ✅ 新增10分鐘後重試機制
- ✅ 優化錯誤處理和退出碼
- ✅ 建立測試腳本驗證機制

### **未來規劃**
- 🔮 根據成功率動態調整重試間隔
- 📊 建立成功率監控儀表板
- 🔔 整合更多通知渠道（Line、Discord等）

---

## 🎯 **重點提醒**

⚠️ **新的執行時間：每日下午3:30**
🔄 **自動重試：如無資料則10分鐘後重試**
📊 **提高可靠性：雙重保障確保資料獲取**

現在的系統更加穩定可靠，能夠應對台期所資料發布時間的變化！ 