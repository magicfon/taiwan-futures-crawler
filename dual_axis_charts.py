#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é›™è»¸åœ–è¡¨ç”Ÿæˆå™¨
ä¸»è»¸ï¼šå¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸ï¼ˆæŸ±ç‹€åœ–ï¼‰
å‰¯è»¸ï¼šå¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸ï¼ˆæŠ˜ç·šåœ–ï¼‰
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import logging
import os
from datetime import datetime, timedelta

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("é›™è»¸åœ–è¡¨ç”Ÿæˆ")

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

def load_latest_data_with_june3():
    """è¼‰å…¥åŒ…å«6/3çš„æœ€æ–°è³‡æ–™"""
    try:
        from google_sheets_manager import GoogleSheetsManager
        
        logger.info("ğŸ” è¼‰å…¥æœ€æ–°Google Sheetsè³‡æ–™ï¼ˆåŒ…å«6/3ï¼‰...")
        
        gm = GoogleSheetsManager()
        spreadsheet = gm.client.open('å°æœŸæ‰€è³‡æ–™åˆ†æ')
        
        # æª¢æŸ¥å¤šå€‹å¯èƒ½çš„å·¥ä½œè¡¨
        worksheets_to_check = ['æ­·å²è³‡æ–™', 'Sheet1', 'æœ€æ–°30å¤©è³‡æ–™']
        
        all_data = []
        
        for ws_name in worksheets_to_check:
            try:
                logger.info(f"ğŸ“– æª¢æŸ¥å·¥ä½œè¡¨: {ws_name}")
                ws = spreadsheet.worksheet(ws_name)
                values = ws.get_all_values()
                
                if len(values) < 2:
                    continue
                
                headers = values[0]
                data_rows = values[1:]
                
                df_temp = pd.DataFrame(data_rows, columns=headers)
                df_temp = df_temp[df_temp['æ—¥æœŸ'].str.strip() != '']
                
                if len(df_temp) > 0:
                    # å˜—è©¦è½‰æ›æ—¥æœŸ
                    df_temp['æ—¥æœŸ'] = pd.to_datetime(df_temp['æ—¥æœŸ'], format='%Y/%m/%d', errors='coerce')
                    df_temp = df_temp.dropna(subset=['æ—¥æœŸ'])
                    
                    if len(df_temp) > 0:
                        logger.info(f"âœ… å¾ {ws_name} è¼‰å…¥ {len(df_temp)} ç­†è³‡æ–™")
                        logger.info(f"ğŸ“… æ—¥æœŸç¯„åœ: {df_temp['æ—¥æœŸ'].min()} åˆ° {df_temp['æ—¥æœŸ'].max()}")
                        all_data.append(df_temp)
            
            except Exception as e:
                logger.debug(f"å·¥ä½œè¡¨ {ws_name} è®€å–å¤±æ•—: {e}")
                continue
        
        if not all_data:
            logger.error("âŒ ç„¡æ³•å¾ä»»ä½•å·¥ä½œè¡¨è¼‰å…¥è³‡æ–™")
            return pd.DataFrame()
        
        # åˆä½µæ‰€æœ‰è³‡æ–™ä¸¦å»é‡
        df = pd.concat(all_data, ignore_index=True)
        df = df.drop_duplicates(subset=['æ—¥æœŸ', 'å¥‘ç´„åç¨±', 'èº«ä»½åˆ¥'])
        
        # è½‰æ›æ•¸å€¼æ¬„ä½
        numeric_cols = ['å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸', 'å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        logger.info(f"ğŸ“Š ç¸½å…±åˆä½µ {len(df)} ç­†å”¯ä¸€è³‡æ–™")
        logger.info(f"ğŸ“… æœ€çµ‚æ—¥æœŸç¯„åœ: {df['æ—¥æœŸ'].min()} åˆ° {df['æ—¥æœŸ'].max()}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰6/3è³‡æ–™
        june_3_data = df[df['æ—¥æœŸ'].dt.date == pd.to_datetime('2025/06/03').date()]
        if not june_3_data.empty:
            logger.info(f"âœ… æ‰¾åˆ°6/3è³‡æ–™: {len(june_3_data)}ç­†")
        else:
            logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°6/3è³‡æ–™ï¼Œæª¢æŸ¥ä»Šå¤©çš„æ—¥æœŸæˆ–å·¥ä½œè¡¨å…§å®¹")
            
            # é¡¯ç¤ºæœ€æ–°å¹¾å¤©çš„è³‡æ–™
            latest_dates = sorted(df['æ—¥æœŸ'].dt.date.unique(), reverse=True)
            logger.info(f"ğŸ“† æœ€æ–°5å€‹æ—¥æœŸ: {latest_dates[:5]}")
        
        # éæ¿¾æœ€è¿‘30å€‹å·¥ä½œæ—¥
        end_date = df['æ—¥æœŸ'].max()  # ä½¿ç”¨è³‡æ–™ä¸­çš„æœ€æ–°æ—¥æœŸï¼Œè€Œä¸æ˜¯ä»Šå¤©
        start_date = end_date - timedelta(days=45)
        
        df_filtered = df[(df['æ—¥æœŸ'] >= start_date) & (df['æ—¥æœŸ'] <= end_date)]
        df_filtered = df_filtered[df_filtered['æ—¥æœŸ'].dt.weekday < 5]
        
        # å–æœ€è¿‘30å€‹å·¥ä½œæ—¥
        unique_dates = sorted(df_filtered['æ—¥æœŸ'].dt.date.unique())
        if len(unique_dates) > 30:
            recent_30_dates = unique_dates[-30:]
            df_filtered = df_filtered[df_filtered['æ—¥æœŸ'].dt.date.isin(recent_30_dates)]
        
        logger.info(f"âœ… éæ¿¾å¾Œæœ‰ {len(df_filtered)} ç­†30å¤©å…§çš„è³‡æ–™")
        logger.info(f"ğŸ“… åˆ†æç¯„åœ: {df_filtered['æ—¥æœŸ'].min().strftime('%Y-%m-%d')} åˆ° {df_filtered['æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
        
        return df_filtered
        
    except Exception as e:
        logger.error(f"âŒ è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
        return pd.DataFrame()

def generate_dual_axis_charts(df, output_dir="dual_axis_charts", aggregate_identities=True):
    """
    ç”Ÿæˆé›™è»¸åœ–è¡¨
    
    Args:
        df: è³‡æ–™DataFrame
        output_dir: è¼¸å‡ºç›®éŒ„
        aggregate_identities: æ˜¯å¦åŠ ç¸½ä¸‰å¤§æ³•äºº
    """
    try:
        os.makedirs(output_dir, exist_ok=True)
        chart_paths = []
        
        # è™•ç†è³‡æ–™
        if aggregate_identities:
            logger.info("ğŸ“Š åŠ ç¸½ä¸‰å¤§æ³•äººè³‡æ–™...")
            df_processed = df.groupby(['æ—¥æœŸ', 'å¥‘ç´„åç¨±']).agg({
                'å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸': 'sum',
                'å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸': 'sum'
            }).reset_index()
        else:
            df_processed = df.copy()
        
        contracts = df_processed['å¥‘ç´„åç¨±'].unique()
        logger.info(f"ğŸ¨ é–‹å§‹ç”Ÿæˆ {len(contracts)} å€‹å¥‘ç´„çš„é›™è»¸åœ–è¡¨...")
        
        for contract in contracts:
            contract_data = df_processed[df_processed['å¥‘ç´„åç¨±'] == contract].copy()
            contract_data = contract_data.sort_values('æ—¥æœŸ')
            
            if contract_data.empty:
                continue
            
            # å‰µå»ºé›™è»¸åœ–è¡¨
            fig, ax1 = plt.subplots(figsize=(15, 8))
            
            # ä¸»è»¸ï¼šäº¤æ˜“å£æ•¸ï¼ˆæŸ±ç‹€åœ–ï¼‰
            bars = ax1.bar(contract_data['æ—¥æœŸ'], contract_data['å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸'], 
                          alpha=0.7, color='#2E86AB', width=0.8, label='å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸')
            
            # è¨­å®šä¸»è»¸
            ax1.set_xlabel('æ—¥æœŸ', fontsize=12, fontweight='bold')
            ax1.set_ylabel('å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸', fontsize=12, fontweight='bold', color='#2E86AB')
            ax1.tick_params(axis='y', labelcolor='#2E86AB')
            ax1.grid(True, alpha=0.3)
            ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.5, linewidth=1)
            
            # å‰¯è»¸ï¼šæœªå¹³å€‰å£æ•¸ï¼ˆæŠ˜ç·šåœ–ï¼‰
            ax2 = ax1.twinx()
            line = ax2.plot(contract_data['æ—¥æœŸ'], contract_data['å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸'], 
                           color='#E74C3C', linewidth=3, marker='o', markersize=6, 
                           label='å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸')
            
            # è¨­å®šå‰¯è»¸
            ax2.set_ylabel('å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸', fontsize=12, fontweight='bold', color='#E74C3C')
            ax2.tick_params(axis='y', labelcolor='#E74C3C')
            ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5, linewidth=1)
            
            # æ¨™é¡Œå’Œæ ¼å¼
            title = f"{contract} å¥‘ç´„ - ä¸‰å¤§æ³•äºº{'æ•´é«”' if aggregate_identities else 'åˆ†åˆ¥'}æŒå€‰åˆ†æ (30å¤©)"
            plt.title(title, fontsize=16, fontweight='bold', pad=20)
            
            # è¨­å®šæ—¥æœŸæ ¼å¼
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
            ax1.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
            plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
            
            # æ·»åŠ åœ–ä¾‹
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=10)
            
            # æ·»åŠ æ•¸å€¼æ¨™ç±¤åˆ°æŸ±ç‹€åœ–ï¼ˆåƒ…é¡¯ç¤ºçµ•å°å€¼è¼ƒå¤§çš„ï¼‰
            for bar, value in zip(bars, contract_data['å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸']):
                if abs(value) > abs(contract_data['å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸']).max() * 0.3:  # åªé¡¯ç¤ºè¼ƒå¤§çš„å€¼
                    height = bar.get_height()
                    ax1.text(bar.get_x() + bar.get_width()/2., height + (abs(height) * 0.05 if height > 0 else -abs(height) * 0.05),
                            f'{int(value):,}', ha='center', va='bottom' if height > 0 else 'top', 
                            fontsize=8, color='#2E86AB', fontweight='bold')
            
            plt.tight_layout()
            
            # å„²å­˜åœ–è¡¨
            filename = f"{contract}_dual_axis_{'aggregated' if aggregate_identities else 'separate'}_30days.png"
            filepath = os.path.join(output_dir, filename)
            plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            
            chart_paths.append(filepath)
            logger.info(f"âœ… å·²ç”Ÿæˆé›™è»¸åœ–è¡¨: {filename}")
        
        return chart_paths
        
    except Exception as e:
        logger.error(f"âŒ é›™è»¸åœ–è¡¨ç”Ÿæˆå¤±æ•—: {e}")
        return []

def generate_report_summary(df, is_aggregated=True):
    """ç”Ÿæˆåˆ†æå ±å‘Šæ‘˜è¦"""
    try:
        if df.empty:
            return "âš ï¸ ç„¡è³‡æ–™å¯åˆ†æ"
        
        date_range = f"{df['æ—¥æœŸ'].min().strftime('%Y-%m-%d')} åˆ° {df['æ—¥æœŸ'].max().strftime('%Y-%m-%d')}"
        unique_dates = df['æ—¥æœŸ'].dt.date.nunique()
        contracts = df['å¥‘ç´„åç¨±'].unique().tolist()
        
        # å¦‚æœæ˜¯åŠ ç¸½æ¨¡å¼ï¼Œå…ˆè™•ç†è³‡æ–™
        if is_aggregated:
            df_summary = df.groupby(['æ—¥æœŸ', 'å¥‘ç´„åç¨±']).agg({
                'å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸': 'sum',
                'å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸': 'sum'
            }).reset_index()
        else:
            df_summary = df.copy()
        
        summary = f"""ğŸ“Š å°æœŸæ‰€ä¸‰å¤§æ³•äººæŒå€‰åˆ†æå ±å‘Š (30å¤©)
ğŸ“… åˆ†ææœŸé–“: {date_range} ({unique_dates}å€‹äº¤æ˜“æ—¥)
ğŸ“ˆ åˆ†æå¥‘ç´„: {', '.join(contracts)}
ğŸ“‹ åœ–è¡¨æ ¼å¼: é›™è»¸åœ–è¡¨ï¼ˆä¸»è»¸æŸ±ç‹€åœ–ï¼šäº¤æ˜“å£æ•¸ï¼Œå‰¯è»¸æŠ˜ç·šåœ–ï¼šæœªå¹³å€‰å£æ•¸ï¼‰
ğŸ·ï¸ è³‡æ–™ä¾†æº: Google Sheetsã€Œå°æœŸæ‰€è³‡æ–™åˆ†æã€

"""
        
        if is_aggregated:
            summary += "ğŸ“Š åˆ†ææ–¹å¼: ä¸‰å¤§æ³•äººï¼ˆå¤–è³‡ã€æŠ•ä¿¡ã€è‡ªç‡Ÿå•†ï¼‰åŠ ç¸½\n\n"
            
            for contract in contracts:
                contract_data = df_summary[df_summary['å¥‘ç´„åç¨±'] == contract].sort_values('æ—¥æœŸ')
                if contract_data.empty:
                    continue
                
                latest_trade = contract_data['å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸'].iloc[-1]
                latest_position = contract_data['å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸'].iloc[-1]
                
                # è¨ˆç®—è¶¨å‹¢
                if len(contract_data) >= 5:
                    recent_trade_avg = contract_data['å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸'].tail(5).mean()
                    recent_position_avg = contract_data['å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸'].tail(5).mean()
                else:
                    recent_trade_avg = latest_trade
                    recent_position_avg = latest_position
                
                trade_trend = "ğŸ“ˆ åå¤š" if recent_trade_avg > 1000 else "ğŸ“‰ åç©º" if recent_trade_avg < -1000 else "â¡ï¸ å¹³è¡¡"
                position_trend = "ğŸ“ˆ åå¤š" if recent_position_avg > 5000 else "ğŸ“‰ åç©º" if recent_position_avg < -5000 else "â¡ï¸ å¹³è¡¡"
                
                summary += f"""ğŸ’¼ {contract}å¥‘ç´„åˆ†æ:
   â€¢ æœ€æ–°æ·¨äº¤æ˜“é‡: {latest_trade:,} å£ {trade_trend}
   â€¢ æœ€æ–°æ·¨æœªå¹³å€‰: {latest_position:,} å£ {position_trend}
   â€¢ 5æ—¥å¹³å‡äº¤æ˜“é‡: {recent_trade_avg:,.0f} å£
   â€¢ 5æ—¥å¹³å‡æœªå¹³å€‰: {recent_position_avg:,.0f} å£

"""
        
        summary += """ğŸ“± åœ–è¡¨èªªæ˜:
â€¢ è—è‰²æŸ±ç‹€åœ–ï¼ˆä¸»è»¸ï¼‰: å¤šç©ºæ·¨é¡äº¤æ˜“å£æ•¸ï¼Œæ­£å€¼è¡¨ç¤ºåå¤šäº¤æ˜“ï¼Œè² å€¼è¡¨ç¤ºåç©ºäº¤æ˜“
â€¢ ç´…è‰²æŠ˜ç·šåœ–ï¼ˆå‰¯è»¸ï¼‰: å¤šç©ºæ·¨é¡æœªå¹³å€‰å£æ•¸ï¼Œæ­£å€¼è¡¨ç¤ºåå¤šæŒå€‰ï¼Œè² å€¼è¡¨ç¤ºåç©ºæŒå€‰
â€¢ 30å¤©å®Œæ•´è¶¨å‹¢åˆ†æï¼ŒåŠ©æ‚¨æŒæ¡ä¸‰å¤§æ³•äººçš„å¸‚å ´å‹•å‘ï¼"""
        
        return summary
        
    except Exception as e:
        logger.error(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}")
        return "âš ï¸ æ‘˜è¦ç”Ÿæˆå¤±æ•—"

def main():
    """ä¸»ç¨‹å¼"""
    try:
        from telegram_notifier import TelegramNotifier
        
        logger.info("=== å°æœŸæ‰€é›™è»¸åœ–è¡¨åˆ†æç³»çµ± ===")
        
        # 1. è¼‰å…¥æœ€æ–°è³‡æ–™
        df = load_latest_data_with_june3()
        
        if df.empty:
            logger.error("âŒ ç„¡æ³•è¼‰å…¥è³‡æ–™")
            return 1
        
        # 2. ç”Ÿæˆé›™è»¸åœ–è¡¨ï¼ˆåŠ ç¸½æ¨¡å¼ï¼‰
        chart_paths = generate_dual_axis_charts(df, aggregate_identities=True)
        
        if not chart_paths:
            logger.error("âŒ åœ–è¡¨ç”Ÿæˆå¤±æ•—")
            return 1
        
        # 3. ç”Ÿæˆåˆ†ææ‘˜è¦
        summary_text = generate_report_summary(df, is_aggregated=True)
        print("\n" + summary_text)
        
        # 4. ç™¼é€åˆ°Telegram
        logger.info("ğŸ“± ç™¼é€é›™è»¸åœ–è¡¨åˆ°Telegram...")
        
        bot_token = "7088578241:AAErbP-EuoRGClRZ3FFfPMjl8k3CFpqgn8E"
        chat_id = "1038401606"
        notifier = TelegramNotifier(bot_token, chat_id)
        
        if notifier.test_connection():
            success = notifier.send_chart_report(chart_paths, summary_text)
            
            if success:
                logger.info("ğŸ‰ é›™è»¸åœ–è¡¨å·²æˆåŠŸç™¼é€åˆ°Telegramï¼")
                logger.info("ğŸ“Š æ–°æ ¼å¼: ä¸»è»¸æŸ±ç‹€åœ–ï¼ˆäº¤æ˜“é‡ï¼‰+ å‰¯è»¸æŠ˜ç·šåœ–ï¼ˆæœªå¹³å€‰ï¼‰")
                return 0
            else:
                logger.error("âŒ Telegramç™¼é€å¤±æ•—")
                return 1
        else:
            logger.error("âŒ Telegramé€£ç·šå¤±æ•—")
            return 1
            
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code) 