# 台期所分階段資料爬取系統

## 📋 功能說明

系統支援分兩個階段爬取台期所資料，對應不同的資料公布時間：

### 🕐 第一階段：交易量資料 (下午2點左右)
- **資料內容**: 多方交易口數、多方契約金額、空方交易口數、空方契約金額、多空淨額交易口數、多空淨額契約金額
- **Google Sheets分頁**: 「交易量資料」
- **執行時機**: 下午2點台期所公布交易量資料後

### 🕐 第二階段：完整資料 (下午3點半左右)  
- **資料內容**: 交易量資料 + 未平倉資料
- **Google Sheets分頁**: 「完整資料」
- **執行時機**: 下午3點半台期所公布未平倉資料後

## 🚀 快速使用

### 方法一：使用批次檔案 (推薦)

#### 下午2點 - 爬取交易量資料
```bash
# 雙擊執行
crawl_trading_data.bat
```

#### 下午3點半 - 爬取完整資料
```bash
# 雙擊執行  
crawl_complete_data.bat
```

#### 智能爬取 - 自動判斷時間
```bash
# 雙擊執行，系統會根據當前時間自動選擇資料類型
crawl_now.bat
```

### 方法二：直接使用命令列

#### 爬取交易量資料
```bash
python taifex_crawler.py --date-range today --contracts TX,TE,MTX --identities ALL --data_type TRADING
```

#### 爬取完整資料
```bash
python taifex_crawler.py --date-range today --contracts TX,TE,MTX --identities ALL --data_type COMPLETE
```

## 🤖 自動排程

### 啟動每日排程器
```bash
# 雙擊執行
start_daily_schedule.bat

# 或使用命令列
python daily_crawler_schedule.py --mode schedule
```

排程器會自動在以下時間執行：
- **週一到週五 14:00**: 爬取交易量資料
- **週一到週五 15:30**: 爬取完整資料

## 📊 Google Sheets 分頁說明

### 「交易量資料」分頁
- 包含下午2點公布的交易量資料
- 欄位：日期、契約名稱、身份別、多方交易口數、多方契約金額、空方交易口數、空方契約金額、多空淨額交易口數、多空淨額契約金額

### 「完整資料」分頁  
- 包含下午3點半公布的完整資料
- 欄位：交易量資料 + 未平倉資料（多方未平倉口數、多方未平倉契約金額、空方未平倉口數、空方未平倉契約金額、多空淨額未平倉口數、多空淨額未平倉契約金額）

## ⚙️ 進階參數

### 資料類型參數
- `--data_type TRADING`: 僅爬取交易量資料
- `--data_type COMPLETE`: 爬取完整資料（默認值）

### 契約參數
- `--contracts TX,TE,MTX`: 指定要爬取的契約
- 可選擇：TX（台指期）、TE（電子期）、MTX（小台指）、ZMX（微台指）、NQF（那斯達克期）

### 身份別參數
- `--identities ALL`: 爬取所有身份別（自營商、投信、外資）
- `--identities 自營商 投信`: 僅爬取指定身份別

### 日期參數
- `--date-range today`: 今天
- `--date-range 2024-01-15`: 指定單日
- `--date-range 2024-01-01,2024-01-31`: 指定範圍

## 💡 使用建議

1. **首次使用**: 建議先執行 `crawl_now.bat` 測試系統是否正常運作

2. **每日使用**: 
   - 下午2點後執行 `crawl_trading_data.bat` 獲取交易量資料
   - 下午3點半後執行 `crawl_complete_data.bat` 獲取完整資料

3. **自動化**: 使用 `start_daily_schedule.bat` 啟動排程器，實現全自動爬取

4. **資料查看**: 
   - Google Sheets會自動更新，可在任何裝置查看
   - 本地也會保存CSV和Excel檔案

## 🔧 故障排除

### 常見問題

1. **Google Sheets連不上**
   - 檢查 `config/google_sheets_credentials.json` 是否正確設定
   - 確認網路連線正常

2. **爬取失敗**
   - 檢查台期所網站是否正常
   - 確認爬取時間是否在交易時間內
   - 嘗試降低 `--max_workers` 和增加 `--delay`

3. **沒有資料**
   - 確認日期是否為交易日（非週末假日）
   - 檢查是否在正確的時間爬取對應資料

## 📝 日誌檔案

- `taifex_crawler.log`: 主要爬蟲日誌
- `daily_schedule.log`: 排程器日誌

## 🆘 技術支援

如果遇到問題，請檢查日誌檔案中的錯誤訊息，或參考程式碼中的註解說明。 